{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Setup Chronos-ZS Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'tirex-ts[gluonts,hfdataset,test]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Load Model and Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tirex import ForecastModel, load_model\n",
    "from tirex.util import select_quantile_subset\n",
    "\n",
    "model: ForecastModel = load_model(\"NX-AI/TiRex\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import datasets\n",
    "import fev\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def eval_task(model, task):\n",
    "    inference_time = 0.0\n",
    "    predictions_per_window = []\n",
    "    for window in task.iter_windows(trust_remote_code=True):\n",
    "        past_data, _ = fev.convert_input_data(\n",
    "            window, adapter=\"datasets\", as_univariate=True\n",
    "        )\n",
    "        past_data = past_data.with_format(\"torch\").cast_column(\n",
    "            \"target\", datasets.Sequence(datasets.Value(\"float32\"))\n",
    "        )\n",
    "        loaded_targets = [t for t in past_data[\"target\"]]\n",
    "\n",
    "        start_time = time.monotonic()\n",
    "        quantiles, means = model.forecast(\n",
    "            loaded_targets, prediction_length=task.horizon\n",
    "        )\n",
    "        inference_time += time.monotonic() - start_time\n",
    "\n",
    "        predictions_dict = {\"predictions\": means}\n",
    "        quantiles_subset = select_quantile_subset(quantiles, task.quantile_levels)\n",
    "        for idx, level in enumerate(task.quantile_levels):\n",
    "            predictions_dict[str(level)] = quantiles_subset[:, :, idx]\n",
    "\n",
    "        predictions_per_window.append(\n",
    "            fev.combine_univariate_predictions_to_multivariate(\n",
    "                datasets.Dataset.from_dict(predictions_dict),\n",
    "                target_columns=task.target_columns,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return predictions_per_window, inference_time\n",
    "\n",
    "\n",
    "benchmark = fev.Benchmark.from_yaml(\n",
    "    \"https://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/tasks.yaml\"\n",
    ")\n",
    "summaries = []\n",
    "for task in benchmark.tasks:\n",
    "    predictions, inference_time = eval_task(model, task)\n",
    "    evaluation_summary = task.evaluation_summary(\n",
    "        predictions,\n",
    "        model_name=\"TiRex\",\n",
    "        inference_time_s=inference_time,\n",
    "    )\n",
    "    print(evaluation_summary)\n",
    "    summaries.append(evaluation_summary)\n",
    "\n",
    "\n",
    "summaries = pd.DataFrame(summaries)\n",
    "summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu124_martinloretz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
